# -*- coding: utf-8 -*-
"""modelling

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_fR6RiHu6DQK-eoQ38p_BAxCffj_6sRW
"""

# Commented out IPython magic to ensure Python compatibility.
# 1) CLONE REPO GITHUB
!rm -rf Eksperimen_SML_Muhammad-Rafi-Insani
!git clone https://github.com/rafi1n/Eksperimen_SML_Muhammad-Rafi-Insani.git
# %cd Eksperimen_SML_Muhammad-Rafi-Insani/Membangun_model
!ls -la

# 2) INSTALL DEPENDENCIES
!pip -q install --upgrade pip
!pip -q install pandas numpy scikit-learn mlflow dagshub matplotlib joblib

# 3) SET ENV VAR UNTUK DAGSHUB
import os
os.environ["DAGSHUB_REPO_OWNER"] = "rafi1n"
os.environ["DAGSHUB_REPO_NAME"]  = "Eksperimen_SML_Muhammad-Rafi-Insani"

# 4) LOGIN DAGSHUB
from getpass import getpass
import os
token = getpass("Paste DAGSHUB TOKEN (tidak tampil): ")
os.environ["DAGSHUB_TOKEN"] = token
print("Token set.")

# 5) INISIALISASI DAGSHUB MLFLOW
import dagshub
repo_owner = os.environ["DAGSHUB_REPO_OWNER"]
repo_name  = os.environ["DAGSHUB_REPO_NAME"]
dagshub.init(repo_owner=repo_owner, repo_name=repo_name, mlflow=True)
print("DagsHub MLflow initialized.")

"""Baseline Run"""

# 6A) BASELINE TRAINING (manual logging)
import os
import json
from datetime import datetime
import numpy as np
import pandas as pd
import mlflow
import mlflow.sklearn
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
from sklearn.linear_model import LogisticRegression

DATA_PATH = "titanic_processed.csv"
TARGET = "Survived"
df = pd.read_csv(DATA_PATH)
X = df.drop(columns=[TARGET]).copy()
y = df[TARGET].copy()

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y)

num_cols = X.select_dtypes(include=[np.number]).columns.tolist()
cat_cols = X.select_dtypes(exclude=[np.number]).columns.tolist()

numeric_tf = Pipeline(steps=[
    ("imputer", SimpleImputer(strategy="median")),
    ("scaler", StandardScaler())])

categorical_tf = Pipeline(steps=[
    ("imputer", SimpleImputer(strategy="most_frequent"))])

preprocessor = ColumnTransformer(
    transformers=[
        ("num", numeric_tf, num_cols),
        ("cat", categorical_tf, cat_cols),
    ],
    remainder="drop")

pipe = Pipeline(steps=[
    ("preprocess", preprocessor),
    ("model", LogisticRegression(max_iter=2000))])

experiment_name = f"titanic_colab_baseline_{datetime.now().strftime('%Y%m%d')}"
mlflow.set_experiment(experiment_name)
with mlflow.start_run(run_name="baseline_logreg_colab"):
    # params
    mlflow.log_param("model", "LogisticRegression")
    mlflow.log_param("test_size", 0.2)
    mlflow.log_param("random_state", 42)
    mlflow.log_param("n_rows", df.shape[0])
    mlflow.log_param("n_features_before", X.shape[1])
    # train
    pipe.fit(X_train, y_train)
    # eval
    y_pred = pipe.predict(X_test)
    try:
        y_proba = pipe.predict_proba(X_test)[:, 1]
        auc = roc_auc_score(y_test, y_proba)
    except Exception:
        auc = None
    acc = accuracy_score(y_test, y_pred)
    prec = precision_score(y_test, y_pred, zero_division=0)
    rec = recall_score(y_test, y_pred, zero_division=0)
    f1 = f1_score(y_test, y_pred, zero_division=0)
    mlflow.log_metric("accuracy", acc)
    mlflow.log_metric("precision", prec)
    mlflow.log_metric("recall", rec)
    mlflow.log_metric("f1", f1)
    if auc is not None:
        mlflow.log_metric("roc_auc", auc)
    # log model
    mlflow.sklearn.log_model(pipe, artifact_path="model")
    # extra artifact:schema
    schema = {
        "target": TARGET,
        "features": list(X.columns),
        "dtypes": {c: str(df[c].dtype) for c in df.columns}}
    os.makedirs("colab_artifacts", exist_ok=True)
    schema_path = "colab_artifacts/schema.json"
    with open(schema_path, "w", encoding="utf-8") as f:
        json.dump(schema, f, indent=2)
    mlflow.log_artifact(schema_path, artifact_path="extras")
print("Baseline done. Cek tab Experiments/MLflow UI di DagsHub.")